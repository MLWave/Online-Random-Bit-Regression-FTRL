# Genetic Classifier Experiment

Out-of-memory Genetic Programming experiments. 

## Data

Digit dataset turned into binary classification problem (all "1"'s and "0"'s).

We use 200 samples for training, rest for testing.

## Epoch 1 (generate population)

Creates 5000 random perceptrons. Weights are random.uniform(-1,1). Variables are a random subset of size 3.

## Epoch 2 (selecting)

Do a bounded sigmoid on the perceptron dotproduct. Compute logistic loss for every perceptron.

## Epoch 3 (validation)

Pick top n (in our case just top 3) perceptrons with lowest loss. Calculate AUC score on their average.

## Todo

Mutation (perturb the weights)
Cross-breeding
Stacked Generalization
Refactor code

## Console
```
(0.014806130485203578, 0)
(0.015559958197744028, 0)
(0.01587381161380923, 0)
(0.0169735033705027, 0)
(0.01717849773878812, 0)
(0.019452516605602196, 0)
(0.019935589575795432, 0)
(0.021776800144591064, 0)
(0.022564160497505852, 0)
(0.024220038565533175, 0)
(0.025746555210662218, 0)
(0.02605650144187907, 0)
(0.026810217179488924, 0)
(0.02713099408186445, 0)
(0.02723356433475863, 0)
(0.02936591408356302, 0)
(0.029978667260524033, 0)
(0.030700550772331376, 0)
(0.030844433504879143, 0)
(0.031053159900509414, 0)
(0.03123725078013455, 0)
(0.03297678325368353, 0)
(0.03332912169404179, 0)
(0.033473004426589556, 0)
(0.033473004426589556, 0)
(0.03433782823002379, 0)
(0.03542307913509152, 0)
(0.036705456537757065, 0)
(0.037034271782880074, 0)
(0.037623925905289714, 0)
(0.038775641856037484, 0)
(0.039960926109952756, 0)
(0.04044573790490704, 0)
(0.04130375894356001, 0)
(0.043281184380554755, 0)
(0.04328179360110455, 0)
(0.04538484473375132, 0)
(0.046783753657153086, 0)
(0.04844416778234802, 0)
(0.048755056454485746, 0)
(0.050116700140464994, 0)
(0.05239087672961318, 0)
(0.05316126249745066, 0)
(0.053315231941341364, 0)
(0.0546916896005725, 0)
(0.05472269649917016, 0)
(0.05554640940178249, 0)
(0.055913721143210526, 0)
(0.055913721143210526, 0)
(0.055913721143210526, 0)
(0.05679474073321927, 0)
(0.05841107658258162, 0)
(0.05912213847818546, 0)
(0.06219733610199696, 0)
(0.06301575070520711, 0)
(0.06301575070520711, 0)
(0.06518628703287722, 0)
(0.0662417195310765, 0)
(0.06791626882271846, 0)
(0.06834706228267, 0)
(0.06872344287821336, 0)
(0.07074219992113444, 0)
(0.07185115914143808, 0)
(0.07330218790504078, 0)
(0.07385290196880523, 0)
(0.07565544253872046, 0)
(0.07618661179570192, 0)
(0.08020173209230932, 0)
(0.08020173209230932, 0)
(0.09218162661712481, 0)
(0.09480643413693064, 0)
(0.10213356194781036, 0)
(0.1060934551977365, 0)
(0.1132913629361838, 0)
(0.11741878733773632, 0)
(0.16301499791048507, 0)
(0.17538128558051155, 0)
(0.20671005402596973, 0)
(0.2516665407893916, 1)
(0.3661389534525756, 1)
(0.4252099449008057, 0)
(0.46393919484645285, 1)
(0.46393919484645285, 1)
(0.5010890570451947, 1)
(0.5612109193335089, 1)
(0.6331774086989662, 1)
(0.7429332849557856, 1)
(0.7628192573041437, 1)
(0.7685918165525977, 1)
(0.7685918165525977, 1)
(0.8570344990295519, 1)
(0.9417282789353449, 1)
(0.9604228201148005, 1)
(0.9676786026688059, 1)
(0.9772060070555658, 1)
(0.9791451785550085, 1)
(0.9842293187007075, 1)
(0.9901488715048538, 1)
(0.990436153644518, 1)
(0.9919238054978897, 1)
(0.9928078540976585, 1)
(0.9933478035260386, 1)
(0.993918811471151, 1)
(0.9949463438751233, 1)
(0.9950517422780601, 1)
(0.9953454365707204, 1)
(0.9957547029560953, 1)
(0.9966372191059513, 1)
(0.9968856510709517, 1)
(0.9968927400719431, 1)
(0.9970405821756699, 1)
(0.9974510717889961, 1)
(0.9976801858304766, 1)
(0.9979552393408241, 1)
(0.9982154865259442, 1)
(0.9982203594383284, 1)
(0.9982840036989512, 1)
(0.998419906033074, 1)
(0.9984286897033879, 1)
(0.9984939983442622, 1)
(0.9985027501741893, 1)
(0.998549118578187, 1)
(0.9986863173788039, 1)
(0.9986995495829957, 1)
(0.9988363408173697, 1)
(0.998854496324887, 1)
(0.998955527610253, 1)
(0.9991916934357409, 1)
(0.99919397823552, 1)
(0.99919397823552, 1)
(0.9992342622785184, 1)
(0.9992840756930583, 1)
(0.9993487207606337, 1)
(0.9993487207606337, 1)
(0.9993665026371147, 1)
(0.9993913467408749, 1)
(0.999412694902663, 1)
(0.9994539795827881, 1)
(0.9994588524951725, 1)
(0.9994663855013514, 1)
(0.9995178058181322, 1)
(0.9995572280200719, 1)
(0.999596894990182, 1)
(0.9996193026734028, 1)
(0.9996382625515509, 1)
(0.9996787062495565, 1)
(0.999718214845872, 1)
(0.9997201285040723, 1)
(0.999781483433603, 1)
(0.999781483433603, 1)
(0.999783492129653, 1)
(0.9997936397792117, 1)
(0.9998102570392101, 1)
(0.999817704188042, 1)
(0.999817704188042, 1)
(0.9998257655652, 1)
(0.9998278518376006, 1)
(0.9998278518376006, 1)
(0.9998278518376006, 1)
(0.9998301101066053, 1)

ROC_AUC_SCORE: 0.999687451164

Top 3 Perceptrons [(random_weight, feature_index)]
[
[(0.6149939955332868, 36), (-0.6191801712762446, 30), (-0.8061383715423533, 50)], 
[(-0.42417643001229877, 29), (0.7619881468846776, 36), (-0.08738675196793921, 47)], 
[(0.4814303936739788, 36), (-0.2050123438980298, 50), (0.36938855845436214, 44)]
]
```